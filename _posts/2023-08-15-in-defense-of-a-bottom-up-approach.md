---
layout: post
title:  In Defense of a Bottom-Up Approach
date:   2023-7-31 20:01:00
categories: ["Reading", "Deep Learning"]
related_posts: false
---

Having recently *completed* the Deep Learning Specialization (DLS) by Andrew Ng and his team at DeepLearning.AI, and having recently *started* the [Practical Deep Learning for Coders](https://course.fast.ai/) (PDLC) course by Jeremy Howard and his team at fast.ai, I thought I would celebrate my thoughts on Ng's teaching style -- and why I think it's so effective.   

The DLS and PDLC course differ strikingly in one obvious way: while the former emphasizes a "bottom-up" style of teaching, the latter emphasizes a "top-down" style. And though I can appreciate the merits of these two different approaches, I am very much glad that I completed the DLS prior to starting the PDLC course. This of course is *not* to detract from fast.ai; to the contrary, to the extent that I have looked at its materials, the PDLC course seems like another great resource from which I can learn more about deep learning. 

But Andrew Ng is a phenomenal instructor, in that he does not suffer from the symptoms of the so-called "[curse of knowledge](https://en.wikipedia.org/wiki/Curse_of_knowledge)" (the cognitive bias that occurs when ones assumes that others have a similar level of knowledge.) Andrew has clearly a strong grasp on deep learning concepts, and it is impressive how well he is able to convey his thoughts at the level of a complete novice. (I was awestruck by this conversation between Ng and Lex Fridman. My favorite moment of the conversation, in particular, is when Andrew emphasizes his intent to do what was is best for the *students*.) His pedigree in no way interferes with what he expects his audience to understand, and he does not hesitate to re-emphasize subtle points. And for that reason, Andrew, within a span of only a few months, is able to give his students the confidence to transition seamlessly from vectorized implementations of neural networks, to, among other things, convolutional neural networks, recurrent neural networks, and transformers. 

If I had to level one complaint against the DLS, it would be that it does not teach one to develop practical applications using deep learning. (You might have heard the oft-quoted line of Richard Feynman's, which reads: "What I cannot create, I do not understand."). To me, then, the DLS and the PDLC course are seemingly the perfect blend: Where Andrew provides the *foundational* skills one needs to *understand* deep learning, Jeremy provides the *practical* skills one needs to implement deep learning models. 

