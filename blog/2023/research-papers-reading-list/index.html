<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Research Papers Reading List | Bradley M. Cardona</title>
    <meta name="author" content="Bradley M. Cardona">
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%97%BB&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="https://www.bcardona.com/css/style.css">
    <link rel="canonical" href="bcardona.com/blog/2023/research-papers-reading-list/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Bradley </span>M. Cardona</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">Writing<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/archives/">Archives</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Research Papers Reading List</h1>
    <p class="post-meta">April 12, 2023</p>
    <p class="post-tags">
      <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>
        ·  
        <a href="/blog/category/reading">
          <i class="fas fa-tag fa-sm"></i> Reading</a>  
          <a href="/blog/category/research-papers">
          <i class="fas fa-tag fa-sm"></i> Research Papers</a>  
          <a href="/blog/category/machine-learning">
          <i class="fas fa-tag fa-sm"></i> Machine Learning</a>  
          

    </p>
  </header>

  <article class="post-content">
    <h1 id="reading">Reading:</h1>
<h4 id="11---survey">1.1 - Survey</h4>
<ul>
  <li>
<strong>[1]</strong> LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “<strong>Deep learning</strong>.” Nature 521.7553 (2015): 436-444. <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Three Giants’ Survey)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20">
</li>
</ul>

<hr>

<h1 id="read">Read:</h1>
<ul>
  <li>To be updated.</li>
</ul>

<hr>

<h1 id="to-read">To Read:</h1>

<h2 id="1---deep-learning-history-and-basics">1 - Deep Learning History and Basics</h2>

<h4 id="10---book">1.0 - Book</h4>
<ul>
  <li>
<strong>[0]</strong> Bengio, Yoshua, Ian J. Goodfellow, and Aaron Courville. “<strong>Deep learning</strong>.” An MIT Press book. (2015). <a href="http://www.deeplearningbook.org/" rel="external nofollow noopener" target="_blank">[html]</a> <strong>(Deep Learning Bible, you can read this book while reading following papers.)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20">
</li>
</ul>

<!-- ## 1.1 Survey
**[1]** LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. "**Deep learning**." Nature 521.7553 (2015): 436-444. [[pdf]](http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf) **(Three Giants' Survey)** :star::star::star::star::star: -->

<h4 id="12---deep-belief-networkdbnmilestone-of-deep-learning-eve">1.2 - Deep Belief Network(DBN)(Milestone of Deep Learning Eve)</h4>

<ul>
  <li>
    <p><strong>[2]</strong> Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. “<strong>A fast learning algorithm for deep belief nets</strong>.” Neural computation 18.7 (2006): 1527-1554. <a href="http://www.cs.toronto.edu/~hinton/absps/ncfast.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><strong>(Deep Learning Eve)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. “<strong>Reducing the dimensionality of data with neural networks</strong>.” Science 313.5786 (2006): 504-507. <a href="http://www.cs.toronto.edu/~hinton/science.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Milestone, Show the promise of deep learning)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="13---imagenet-evolutiondeep-learning-broke-out-from-here">1.3 - ImageNet Evolution（Deep Learning broke out from here）</h4>

<ul>
  <li>
    <p><strong>[4]</strong> Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. “<strong>Imagenet classification with deep convolutional neural networks</strong>.” Advances in neural information processing systems. 2012. <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(AlexNet, Deep Learning Breakthrough)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[5]</strong> Simonyan, Karen, and Andrew Zisserman. “<strong>Very deep convolutional networks for large-scale image recognition</strong>.” arXiv preprint arXiv:1409.1556 (2014). <a href="https://arxiv.org/pdf/1409.1556.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(VGGNet,Neural Networks become very deep!)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[6]</strong> Szegedy, Christian, et al. “<strong>Going deeper with convolutions</strong>.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015. <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(GoogLeNet)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[7]</strong> He, Kaiming, et al. “<strong>Deep residual learning for image recognition</strong>.” arXiv preprint arXiv:1512.03385 (2015). <a href="https://arxiv.org/pdf/1512.03385.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(ResNet,Very very deep networks, CVPR best paper)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="14---speech-recognition-evolution">1.4 - Speech Recognition Evolution</h4>

<ul>
  <li>
    <p><strong>[8]</strong> Hinton, Geoffrey, et al. “<strong>Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</strong>.” IEEE Signal Processing Magazine 29.6 (2012): 82-97. <a href="http://cs224d.stanford.edu/papers/maas_paper.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Breakthrough in speech recognition)</strong><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[9]</strong> Graves, Alex, Abdel-rahman Mohamed, and Geoffrey Hinton. “<strong>Speech recognition with deep recurrent neural networks</strong>.” 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. <a href="http://arxiv.org/pdf/1303.5778.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(RNN)</strong><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[10]</strong> Graves, Alex, and Navdeep Jaitly. “<strong>Towards End-To-End Speech Recognition with Recurrent Neural Networks</strong>.” ICML. Vol. 14. 2014. <a href="http://www.jmlr.org/proceedings/papers/v32/graves14.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[11]</strong> Sak, Haşim, et al. “<strong>Fast and accurate recurrent neural network acoustic models for speech recognition</strong>.” arXiv preprint arXiv:1507.06947 (2015). <a href="http://arxiv.org/pdf/1507.06947" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Google Speech Recognition System)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[12]</strong> Amodei, Dario, et al. “<strong>Deep speech 2: End-to-end speech recognition in english and mandarin</strong>.” arXiv preprint arXiv:1512.02595 (2015). <a href="https://arxiv.org/pdf/1512.02595.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Baidu Speech Recognition System)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[13]</strong> W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig “<strong>Achieving Human Parity in Conversational Speech Recognition</strong>.” arXiv preprint arXiv:1610.05256 (2016). <a href="https://arxiv.org/pdf/1610.05256v1" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(State-of-the-art in speech recognition, Microsoft)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<blockquote>
  <p>After reading above papers, you will have a basic understanding of the Deep Learning history, the basic architectures of Deep Learning model(including CNN, RNN, LSTM) and how deep learning can be applied to image and speech recognition issues. The following papers will take you in-depth understanding of the Deep Learning method, Deep Learning in different areas of application and the frontiers. I suggest that you can choose the following papers based on your interests and research direction.</p>
</blockquote>

<h2 id="2---deep-learning-method">2 - Deep Learning Method</h2>

<h4 id="21---model">2.1 - Model</h4>

<ul>
  <li>
    <p><strong>[14]</strong> Hinton, Geoffrey E., et al. “<strong>Improving neural networks by preventing co-adaptation of feature detectors</strong>.” arXiv preprint arXiv:1207.0580 (2012). <a href="https://arxiv.org/pdf/1207.0580.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Dropout)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[15]</strong> Srivastava, Nitish, et al. “<strong>Dropout: a simple way to prevent neural networks from overfitting</strong>.” Journal of Machine Learning Research 15.1 (2014): 1929-1958. <a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[16]</strong> Ioffe, Sergey, and Christian Szegedy. “<strong>Batch normalization: Accelerating deep network training by reducing internal covariate shift</strong>.” arXiv preprint arXiv:1502.03167 (2015). <a href="http://arxiv.org/pdf/1502.03167" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(An outstanding Work in 2015)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[17]</strong> Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. “<strong>Layer normalization</strong>.” arXiv preprint arXiv:1607.06450 (2016). <a href="https://arxiv.org/pdf/1607.06450.pdf?utm_source=sciontist.com&amp;utm_medium=refer&amp;utm_campaign=promote" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Update of Batch Normalization)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[18]</strong> Courbariaux, Matthieu, et al. “<strong>Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to+ 1 or−1</strong>.” <a href="https://pdfs.semanticscholar.org/f832/b16cb367802609d91d400085eb87d630212a.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(New Model,Fast)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[19]</strong> Jaderberg, Max, et al. “<strong>Decoupled neural interfaces using synthetic gradients</strong>.” arXiv preprint arXiv:1608.05343 (2016). <a href="https://arxiv.org/pdf/1608.05343" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Innovation of Training Method,Amazing Work)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[20]</strong> Chen, Tianqi, Ian Goodfellow, and Jonathon Shlens. “Net2net: Accelerating learning via knowledge transfer.” arXiv preprint arXiv:1511.05641 (2015). <a href="https://arxiv.org/abs/1511.05641" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Modify previously trained network to reduce training epochs)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[21]</strong> Wei, Tao, et al. “Network Morphism.” arXiv preprint arXiv:1603.01670 (2016). <a href="https://arxiv.org/abs/1603.01670" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Modify previously trained network to reduce training epochs)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="22---optimization">2.2 - Optimization</h4>

<ul>
  <li>
    <p><strong>[22]</strong> Sutskever, Ilya, et al. “<strong>On the importance of initialization and momentum in deep learning</strong>.” ICML (3) 28 (2013): 1139-1147. <a href="http://www.jmlr.org/proceedings/papers/v28/sutskever13.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Momentum optimizer)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[23]</strong> Kingma, Diederik, and Jimmy Ba. “<strong>Adam: A method for stochastic optimization</strong>.” arXiv preprint arXiv:1412.6980 (2014). <a href="http://arxiv.org/pdf/1412.6980" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Maybe used most often currently)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[24]</strong> Andrychowicz, Marcin, et al. “<strong>Learning to learn by gradient descent by gradient descent</strong>.” arXiv preprint arXiv:1606.04474 (2016). <a href="https://arxiv.org/pdf/1606.04474" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Neural Optimizer,Amazing Work)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[25]</strong> Han, Song, Huizi Mao, and William J. Dally. “<strong>Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding</strong>.” CoRR, abs/1510.00149 2 (2015). <a href="https://pdfs.semanticscholar.org/5b6c/9dda1d88095fa4aac1507348e498a1f2e863.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(ICLR best paper, new direction to make NN running fast,DeePhi Tech Startup)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[26]</strong> Iandola, Forrest N., et al. “<strong>SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&lt; 1MB model size</strong>.” arXiv preprint arXiv:1602.07360 (2016). <a href="http://arxiv.org/pdf/1602.07360" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Also a new direction to optimize NN,DeePhi Tech Startup)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[27]</strong> Glorat Xavier, Bengio Yoshua, et al. “<strong>Understanding the difficulty of training deep forward neural networks</strong>.” Proceedings of the thirteenth International Conference on Artificial Intelligence and Statistics, PMLR 9:249-256,2010. <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="23---unsupervised-learning--deep-generative-model">2.3 - Unsupervised Learning / Deep Generative Model</h4>

<ul>
  <li>
    <p><strong>[28]</strong> Le, Quoc V. “<strong>Building high-level features using large scale unsupervised learning</strong>.” 2013 IEEE international conference on acoustics, speech and signal processing. IEEE, 2013. <a href="http://arxiv.org/pdf/1112.6209.pdf&amp;embed" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Milestone, Andrew Ng, Google Brain Project, Cat)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[29]</strong> Kingma, Diederik P., and Max Welling. “<strong>Auto-encoding variational bayes</strong>.” arXiv preprint arXiv:1312.6114 (2013). <a href="http://arxiv.org/pdf/1312.6114" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(VAE)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[30]</strong> Goodfellow, Ian, et al. “<strong>Generative adversarial nets</strong>.” Advances in Neural Information Processing Systems. 2014. <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(GAN,super cool idea)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[31]</strong> Radford, Alec, Luke Metz, and Soumith Chintala. “<strong>Unsupervised representation learning with deep convolutional generative adversarial networks</strong>.” arXiv preprint arXiv:1511.06434 (2015). <a href="http://arxiv.org/pdf/1511.06434" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(DCGAN)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[32]</strong> Gregor, Karol, et al. “<strong>DRAW: A recurrent neural network for image generation</strong>.” arXiv preprint arXiv:1502.04623 (2015). <a href="http://jmlr.org/proceedings/papers/v37/gregor15.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(VAE with attention, outstanding work)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[33]</strong> Oord, Aaron van den, Nal Kalchbrenner, and Koray Kavukcuoglu. “<strong>Pixel recurrent neural networks</strong>.” arXiv preprint arXiv:1601.06759 (2016). <a href="http://arxiv.org/pdf/1601.06759" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(PixelRNN)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[34]</strong> Oord, Aaron van den, et al. “Conditional image generation with PixelCNN decoders.” arXiv preprint arXiv:1606.05328 (2016). <a href="https://arxiv.org/pdf/1606.05328" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(PixelCNN)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[34]</strong> S. Mehri et al., “<strong>SampleRNN: An Unconditional End-to-End Neural Audio Generation Model</strong>.” arXiv preprint arXiv:1612.07837 (2016). <a href="https://arxiv.org/pdf/1612.07837.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="24---rnn--sequence-to-sequence-model">2.4 - RNN / Sequence-to-Sequence Model</h4>

<ul>
  <li>
    <p><strong>[35]</strong> Graves, Alex. “<strong>Generating sequences with recurrent neural networks</strong>.” arXiv preprint arXiv:1308.0850 (2013). <a href="http://arxiv.org/pdf/1308.0850" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(LSTM, very nice generating result, show the power of RNN)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[36]</strong> Cho, Kyunghyun, et al. “<strong>Learning phrase representations using RNN encoder-decoder for statistical machine translation</strong>.” arXiv preprint arXiv:1406.1078 (2014). <a href="http://arxiv.org/pdf/1406.1078" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(First Seq-to-Seq Paper)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[37]</strong> Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. “<strong>Sequence to sequence learning with neural networks</strong>.” Advances in neural information processing systems. 2014. <a href="https://arxiv.org/pdf/1409.3215.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Outstanding Work)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[38]</strong> Bahdanau, Dzmitry, KyungHyun Cho, and Yoshua Bengio. “<strong>Neural Machine Translation by Jointly Learning to Align and Translate</strong>.” arXiv preprint arXiv:1409.0473 (2014). <a href="https://arxiv.org/pdf/1409.0473v7.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[39]</strong> Vinyals, Oriol, and Quoc Le. “<strong>A neural conversational model</strong>.” arXiv preprint arXiv:1506.05869 (2015). <a href="http://arxiv.org/pdf/1506.05869.pdf%20(http://arxiv.org/pdf/1506.05869.pdf)" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Seq-to-Seq on Chatbot)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="25---neural-turing-machine">2.5 - Neural Turing Machine</h4>

<ul>
  <li>
    <p><strong>[40]</strong> Graves, Alex, Greg Wayne, and Ivo Danihelka. “<strong>Neural turing machines</strong>.” arXiv preprint arXiv:1410.5401 (2014). <a href="http://arxiv.org/pdf/1410.5401.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Basic Prototype of Future Computer)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[41]</strong> Zaremba, Wojciech, and Ilya Sutskever. “<strong>Reinforcement learning neural Turing machines</strong>.” arXiv preprint arXiv:1505.00521 362 (2015). <a href="https://pdfs.semanticscholar.org/f10e/071292d593fef939e6ef4a59baf0bb3a6c2b.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[42]</strong> Weston, Jason, Sumit Chopra, and Antoine Bordes. “<strong>Memory networks</strong>.” arXiv preprint arXiv:1410.3916 (2014). <a href="http://arxiv.org/pdf/1410.3916" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[43]</strong> Sukhbaatar, Sainbayar, Jason Weston, and Rob Fergus. “<strong>End-to-end memory networks</strong>.” Advances in neural information processing systems. 2015. <a href="http://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[44]</strong> Vinyals, Oriol, Meire Fortunato, and Navdeep Jaitly. “<strong>Pointer networks</strong>.” Advances in Neural Information Processing Systems. 2015. <a href="http://papers.nips.cc/paper/5866-pointer-networks.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[45]</strong> Graves, Alex, et al. “<strong>Hybrid computing using a neural network with dynamic external memory</strong>.” Nature (2016). <a href="https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Milestone,combine above papers’ ideas)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="26---deep-reinforcement-learning">2.6 - Deep Reinforcement Learning</h4>

<ul>
  <li>
    <p><strong>[46]</strong> Mnih, Volodymyr, et al. “<strong>Playing atari with deep reinforcement learning</strong>.” arXiv preprint arXiv:1312.5602 (2013). <a href="http://arxiv.org/pdf/1312.5602.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a>) <strong>(First Paper named deep reinforcement learning)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[47]</strong> Mnih, Volodymyr, et al. “<strong>Human-level control through deep reinforcement learning</strong>.” Nature 518.7540 (2015): 529-533. <a href="https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Milestone)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[48]</strong> Wang, Ziyu, Nando de Freitas, and Marc Lanctot. “<strong>Dueling network architectures for deep reinforcement learning</strong>.” arXiv preprint arXiv:1511.06581 (2015). <a href="http://arxiv.org/pdf/1511.06581" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(ICLR best paper,great idea)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[49]</strong> Mnih, Volodymyr, et al. “<strong>Asynchronous methods for deep reinforcement learning</strong>.” arXiv preprint arXiv:1602.01783 (2016). <a href="http://arxiv.org/pdf/1602.01783" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(State-of-the-art method)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[50]</strong> Lillicrap, Timothy P., et al. “<strong>Continuous control with deep reinforcement learning</strong>.” arXiv preprint arXiv:1509.02971 (2015). <a href="http://arxiv.org/pdf/1509.02971" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(DDPG)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[51]</strong> Gu, Shixiang, et al. “<strong>Continuous Deep Q-Learning with Model-based Acceleration</strong>.” arXiv preprint arXiv:1603.00748 (2016). <a href="http://arxiv.org/pdf/1603.00748" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(NAF)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[52]</strong> Schulman, John, et al. “<strong>Trust region policy optimization</strong>.” CoRR, abs/1502.05477 (2015). <a href="http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(TRPO)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[53]</strong> Silver, David, et al. “<strong>Mastering the game of Go with deep neural networks and tree search</strong>.” Nature 529.7587 (2016): 484-489. <a href="http://willamette.edu/~levenick/cs448/goNature.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(AlphaGo)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="27---deep-transfer-learning--lifelong-learning--especially-for-rl">2.7 - Deep Transfer Learning / Lifelong Learning / especially for RL</h4>

<ul>
  <li>
    <p><strong>[54]</strong> Bengio, Yoshua. “<strong>Deep Learning of Representations for Unsupervised and Transfer Learning</strong>.” ICML Unsupervised and Transfer Learning 27 (2012): 17-36. <a href="http://www.jmlr.org/proceedings/papers/v27/bengio12a/bengio12a.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(A Tutorial)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[55]</strong> Silver, Daniel L., Qiang Yang, and Lianghao Li. “<strong>Lifelong Machine Learning Systems: Beyond Learning Algorithms</strong>.” AAAI Spring Symposium: Lifelong Machine Learning. 2013. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.696.7800&amp;rep=rep1&amp;type=pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(A brief discussion about lifelong learning)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[56]</strong> Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. “<strong>Distilling the knowledge in a neural network</strong>.” arXiv preprint arXiv:1503.02531 (2015). <a href="http://arxiv.org/pdf/1503.02531" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Godfather’s Work)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[57]</strong> Rusu, Andrei A., et al. “<strong>Policy distillation</strong>.” arXiv preprint arXiv:1511.06295 (2015). <a href="http://arxiv.org/pdf/1511.06295" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(RL domain)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[58]</strong> Parisotto, Emilio, Jimmy Lei Ba, and Ruslan Salakhutdinov. “<strong>Actor-mimic: Deep multitask and transfer reinforcement learning</strong>.” arXiv preprint arXiv:1511.06342 (2015). <a href="http://arxiv.org/pdf/1511.06342" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(RL domain)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[59]</strong> Rusu, Andrei A., et al. “<strong>Progressive neural networks</strong>.” arXiv preprint arXiv:1606.04671 (2016). <a href="https://arxiv.org/pdf/1606.04671" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Outstanding Work, A novel idea)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="28---one-shot-deep-learning">2.8 - One Shot Deep Learning</h4>

<ul>
  <li>
    <p><strong>[60]</strong> Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. “<strong>Human-level concept learning through probabilistic program induction</strong>.” Science 350.6266 (2015): 1332-1338. <a href="http://clm.utexas.edu/compjclub/wp-content/uploads/2016/02/lake2015.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(No Deep Learning,but worth reading)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[61]</strong> Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. “<strong>Siamese Neural Networks for One-shot Image Recognition</strong>.”(2015) <a href="http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[62]</strong> Santoro, Adam, et al. “<strong>One-shot Learning with Memory-Augmented Neural Networks</strong>.” arXiv preprint arXiv:1605.06065 (2016). <a href="http://arxiv.org/pdf/1605.06065" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(A basic step to one shot learning)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[63]</strong> Vinyals, Oriol, et al. “<strong>Matching Networks for One Shot Learning</strong>.” arXiv preprint arXiv:1606.04080 (2016). <a href="https://arxiv.org/pdf/1606.04080" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[64]</strong> Hariharan, Bharath, and Ross Girshick. “<strong>Low-shot visual object recognition</strong>.” arXiv preprint arXiv:1606.02819 (2016). <a href="http://arxiv.org/pdf/1606.02819" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(A step to large data)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h2 id="3---applications">3 - Applications</h2>

<h4 id="31---nlpnatural-language-processing">3.1 - NLP(Natural Language Processing)</h4>

<ul>
  <li>
    <p><strong>[1]</strong> Antoine Bordes, et al. “<strong>Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing</strong>.” AISTATS(2012) <a href="https://www.hds.utc.fr/~bordesan/dokuwiki/lib/exe/fetch.php?id=en%3Apubli&amp;cache=cache&amp;media=en:bordes12aistats.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[2]</strong> Mikolov, et al. “<strong>Distributed representations of words and phrases and their compositionality</strong>.” ANIPS(2013): 3111-3119 <a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(word2vec)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> Sutskever, et al. “<strong>“Sequence to sequence learning with neural networks</strong>.” ANIPS(2014) <a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[4]</strong> Ankit Kumar, et al. “<strong>“Ask Me Anything: Dynamic Memory Networks for Natural Language Processing</strong>.” arXiv preprint arXiv:1506.07285(2015) <a href="https://arxiv.org/abs/1506.07285" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[5]</strong> Yoon Kim, et al. “<strong>Character-Aware Neural Language Models</strong>.” NIPS(2015) arXiv preprint arXiv:1508.06615(2015) <a href="https://arxiv.org/abs/1508.06615" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[6]</strong> Jason Weston, et al. “<strong>Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks</strong>.” arXiv preprint arXiv:1502.05698(2015) <a href="https://arxiv.org/abs/1502.05698" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(bAbI tasks)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[7]</strong> Karl Moritz Hermann, et al. “<strong>Teaching Machines to Read and Comprehend</strong>.” arXiv preprint arXiv:1506.03340(2015) <a href="https://arxiv.org/abs/1506.03340" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(CNN/DailyMail cloze style questions)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[8]</strong> Alexis Conneau, et al. “<strong>Very Deep Convolutional Networks for Natural Language Processing</strong>.” arXiv preprint arXiv:1606.01781(2016) <a href="https://arxiv.org/abs/1606.01781" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(state-of-the-art in text classification)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[9]</strong> Armand Joulin, et al. “<strong>Bag of Tricks for Efficient Text Classification</strong>.” arXiv preprint arXiv:1607.01759(2016) <a href="https://arxiv.org/abs/1607.01759" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(slightly worse than state-of-the-art, but a lot faster)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="32---object-detection">3.2 - Object Detection</h4>

<ul>
  <li>
    <p><strong>[1]</strong> Szegedy, Christian, Alexander Toshev, and Dumitru Erhan. “<strong>Deep neural networks for object detection</strong>.” Advances in Neural Information Processing Systems. 2013. <a href="http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[2]</strong> Girshick, Ross, et al. “<strong>Rich feature hierarchies for accurate object detection and semantic segmentation</strong>.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2014. <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(RCNN)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> He, Kaiming, et al. “<strong>Spatial pyramid pooling in deep convolutional networks for visual recognition</strong>.” European Conference on Computer Vision. Springer International Publishing, 2014. <a href="http://arxiv.org/pdf/1406.4729" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(SPPNet)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[4]</strong> Girshick, Ross. “<strong>Fast r-cnn</strong>.” Proceedings of the IEEE International Conference on Computer Vision. 2015. <a href="https://pdfs.semanticscholar.org/8f67/64a59f0d17081f2a2a9d06f4ed1cdea1a0ad.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[5]</strong> Ren, Shaoqing, et al. “<strong>Faster R-CNN: Towards real-time object detection with region proposal networks</strong>.” Advances in neural information processing systems. 2015. <a href="https://arxiv.org/pdf/1506.01497.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[6]</strong> Redmon, Joseph, et al. “<strong>You only look once: Unified, real-time object detection</strong>.” arXiv preprint arXiv:1506.02640 (2015). <a href="http://homes.cs.washington.edu/~ali/papers/YOLO.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(YOLO,Oustanding Work, really practical)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[7]</strong> Liu, Wei, et al. “<strong>SSD: Single Shot MultiBox Detector</strong>.” arXiv preprint arXiv:1512.02325 (2015). <a href="http://arxiv.org/pdf/1512.02325" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[8]</strong> Dai, Jifeng, et al. “**R-FCN: Object Detection via</p>
  </li>
</ul>

<p>Region-based Fully Convolutional Networks**.” arXiv preprint arXiv:1605.06409 (2016). <a href="https://arxiv.org/abs/1605.06409" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>

<ul>
  <li>
    <p><strong>[9]</strong> He, Gkioxari, et al. “<strong>Mask R-CNN</strong>” arXiv preprint arXiv:1703.06870 (2017). <a href="https://arxiv.org/abs/1703.06870" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[10]</strong> Bochkovskiy, Alexey, et al. “<strong>YOLOv4: Optimal Speed and Accuracy of Object Detection.</strong>” arXiv preprint arXiv:2004.10934 (2020). <a href="https://arxiv.org/pdf/2004.10934" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[11]</strong> Tan, Mingxing, et al. “<strong>EfficientDet: Scalable and Efficient Object Detection.</strong>” arXiv preprint arXiv:1911.09070 (2019). <a href="https://arxiv.org/pdf/1911.09070" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="33---visual-tracking">3.3 - Visual Tracking</h4>

<ul>
  <li>
    <p><strong>[1]</strong> Wang, Naiyan, and Dit-Yan Yeung. “<strong>Learning a deep compact image representation for visual tracking</strong>.” Advances in neural information processing systems. 2013. <a href="http://papers.nips.cc/paper/5192-learning-a-deep-compact-image-representation-for-visual-tracking.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(First Paper to do visual tracking using Deep Learning,DLT Tracker)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[2]</strong> Wang, Naiyan, et al. “<strong>Transferring rich feature hierarchies for robust visual tracking</strong>.” arXiv preprint arXiv:1501.04587 (2015). <a href="http://arxiv.org/pdf/1501.04587" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(SO-DLT)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> Wang, Lijun, et al. “<strong>Visual tracking with fully convolutional networks</strong>.” Proceedings of the IEEE International Conference on Computer Vision. 2015. <a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Wang_Visual_Tracking_With_ICCV_2015_paper.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(FCNT)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[4]</strong> Held, David, Sebastian Thrun, and Silvio Savarese. “<strong>Learning to Track at 100 FPS with Deep Regression Networks</strong>.” arXiv preprint arXiv:1604.01802 (2016). <a href="http://arxiv.org/pdf/1604.01802" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(GOTURN,Really fast as a deep learning method,but still far behind un-deep-learning methods)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[5]</strong> Bertinetto, Luca, et al. “<strong>Fully-Convolutional Siamese Networks for Object Tracking</strong>.” arXiv preprint arXiv:1606.09549 (2016). <a href="https://arxiv.org/pdf/1606.09549" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(SiameseFC,New state-of-the-art for real-time object tracking)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[6]</strong> Martin Danelljan, Andreas Robinson, Fahad Khan, Michael Felsberg. “<strong>Beyond Correlation Filters: Learning Continuous Convolution Operators for Visual Tracking</strong>.” ECCV (2016) <a href="http://www.cvl.isy.liu.se/research/objrec/visualtracking/conttrack/C-COT_ECCV16.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(C-COT)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[7]</strong> Nam, Hyeonseob, Mooyeol Baek, and Bohyung Han. “<strong>Modeling and Propagating CNNs in a Tree Structure for Visual Tracking</strong>.” arXiv preprint arXiv:1608.07242 (2016). <a href="https://arxiv.org/pdf/1608.07242" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(VOT2016 Winner,TCNN)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="34--image-caption">3.4- Image Caption</h4>

<ul>
  <li>
    <p><strong>[1]</strong> Farhadi,Ali,etal. “<strong>Every picture tells a story: Generating sentences from images</strong>”. In Computer VisionECCV 2010. Springer Berlin Heidelberg:15-29, 2010. <a href="https://www.cs.cmu.edu/~afarhadi/papers/sentence.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[2]</strong> Kulkarni, Girish, et al. “<strong>Baby talk: Understanding and generating image descriptions</strong>”. In Proceedings of the 24th CVPR, 2011. <a href="http://tamaraberg.com/papers/generation_cvpr11.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> Vinyals, Oriol, et al. “<strong>Show and tell: A neural image caption generator</strong>”. In arXiv preprint arXiv:1411.4555, 2014. <a href="https://arxiv.org/pdf/1411.4555.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[4]</strong> Donahue, Jeff, et al. “<strong>Long-term recurrent convolutional networks for visual recognition and description</strong>”. In arXiv preprint arXiv:1411.4389 ,2014. <a href="https://arxiv.org/pdf/1411.4389.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a></p>
  </li>
  <li>
    <p><strong>[5]</strong> Karpathy, Andrej, and Li Fei-Fei. “<strong>Deep visual-semantic alignments for generating image descriptions</strong>”. In arXiv preprint arXiv:1412.2306, 2014. <a href="https://cs.stanford.edu/people/karpathy/cvpr2015.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[6]</strong> Karpathy, Andrej, Armand Joulin, and Fei Fei F. Li. “<strong>Deep fragment embeddings for bidirectional image sentence mapping</strong>”. In Advances in neural information processing systems, 2014. <a href="https://arxiv.org/pdf/1406.5679v1.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[7]</strong> Fang, Hao, et al. “<strong>From captions to visual concepts and back</strong>”. In arXiv preprint arXiv:1411.4952, 2014. <a href="https://arxiv.org/pdf/1411.4952v3.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[8]</strong> Chen, Xinlei, and C. Lawrence Zitnick. “<strong>Learning a recurrent visual representation for image caption generation</strong>”. In arXiv preprint arXiv:1411.5654, 2014. <a href="https://arxiv.org/pdf/1411.5654v1.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[9]</strong> Mao, Junhua, et al. “<strong>Deep captioning with multimodal recurrent neural networks (m-rnn)</strong>”. In arXiv preprint arXiv:1412.6632, 2014. <a href="https://arxiv.org/pdf/1412.6632v5.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[10]</strong> Xu, Kelvin, et al. “<strong>Show, attend and tell: Neural image caption generation with visual attention</strong>”. In arXiv preprint arXiv:1502.03044, 2015. <a href="https://arxiv.org/pdf/1502.03044v3.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="35---machine-translation">3.5 - Machine Translation</h4>

<blockquote>
  <p>Some milestone papers are listed in RNN / Seq-to-Seq topic.</p>
</blockquote>

<ul>
  <li>
    <p><strong>[1]</strong> Luong, Minh-Thang, et al. “<strong>Addressing the rare word problem in neural machine translation</strong>.” arXiv preprint arXiv:1410.8206 (2014). <a href="http://arxiv.org/pdf/1410.8206" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[2]</strong> Sennrich, et al. “<strong>Neural Machine Translation of Rare Words with Subword Units</strong>”. In arXiv preprint arXiv:1508.07909, 2015. <a href="https://arxiv.org/pdf/1508.07909.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> Luong, Minh-Thang, Hieu Pham, and Christopher D. Manning. “<strong>Effective approaches to attention-based neural machine translation</strong>.” arXiv preprint arXiv:1508.04025 (2015). <a href="http://arxiv.org/pdf/1508.04025" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[4]</strong> Chung, et al. “<strong>A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation</strong>”. In arXiv preprint arXiv:1603.06147, 2016. <a href="https://arxiv.org/pdf/1603.06147.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[5]</strong> Lee, et al. “<strong>Fully Character-Level Neural Machine Translation without Explicit Segmentation</strong>”. In arXiv preprint arXiv:1610.03017, 2016. <a href="https://arxiv.org/pdf/1610.03017.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[6]</strong> Wu, Schuster, Chen, Le, et al. “<strong>Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</strong>”. In arXiv preprint arXiv:1609.08144v2, 2016. <a href="https://arxiv.org/pdf/1609.08144v2.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Milestone)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="36---robotics">3.6 - Robotics</h4>

<ul>
  <li>
    <p><strong>[1]</strong> Koutník, Jan, et al. “<strong>Evolving large-scale neural networks for vision-based reinforcement learning</strong>.” Proceedings of the 15th annual conference on Genetic and evolutionary computation. ACM, 2013. <a href="http://repository.supsi.ch/4550/1/koutnik2013gecco.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[2]</strong> Levine, Sergey, et al. “<strong>End-to-end training of deep visuomotor policies</strong>.” Journal of Machine Learning Research 17.39 (2016): 1-40. <a href="http://www.jmlr.org/papers/volume17/15-522/15-522.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> Pinto, Lerrel, and Abhinav Gupta. “<strong>Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours</strong>.” arXiv preprint arXiv:1509.06825 (2015). <a href="http://arxiv.org/pdf/1509.06825" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[4]</strong> Levine, Sergey, et al. “<strong>Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection</strong>.” arXiv preprint arXiv:1603.02199 (2016). <a href="http://arxiv.org/pdf/1603.02199" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[5]</strong> Zhu, Yuke, et al. “<strong>Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning</strong>.” arXiv preprint arXiv:1609.05143 (2016). <a href="https://arxiv.org/pdf/1609.05143" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[6]</strong> Yahya, Ali, et al. “<strong>Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search</strong>.” arXiv preprint arXiv:1610.00673 (2016). <a href="https://arxiv.org/pdf/1610.00673" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[7]</strong> Gu, Shixiang, et al. “<strong>Deep Reinforcement Learning for Robotic Manipulation</strong>.” arXiv preprint arXiv:1610.00633 (2016). <a href="https://arxiv.org/pdf/1610.00633" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[8]</strong> A Rusu, M Vecerik, Thomas Rothörl, N Heess, R Pascanu, R Hadsell.”<strong>Sim-to-Real Robot Learning from Pixels with Progressive Nets</strong>.” arXiv preprint arXiv:1610.04286 (2016). <a href="https://arxiv.org/pdf/1610.04286.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[9]</strong> Mirowski, Piotr, et al. “<strong>Learning to navigate in complex environments</strong>.” arXiv preprint arXiv:1611.03673 (2016). <a href="https://arxiv.org/pdf/1611.03673" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="37---art">3.7 - Art</h4>

<ul>
  <li>
<strong>[1]</strong> Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). “<strong>Inceptionism: Going Deeper into Neural Networks</strong>”. Google Research. <a href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" rel="external nofollow noopener" target="_blank">[html]</a> <strong>(Deep Dream)</strong>
</li>
</ul>

<p><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>

<ul>
  <li>
    <p><strong>[2]</strong> Gatys, Leon A., Alexander S. Ecker, and Matthias Bethge. “<strong>A neural algorithm of artistic style</strong>.” arXiv preprint arXiv:1508.06576 (2015). <a href="http://arxiv.org/pdf/1508.06576" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Outstanding Work, most successful method currently)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> Zhu, Jun-Yan, et al. “<strong>Generative Visual Manipulation on the Natural Image Manifold</strong>.” European Conference on Computer Vision. Springer International Publishing, 2016. <a href="https://arxiv.org/pdf/1609.03552" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(iGAN)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[4]</strong> Champandard, Alex J. “<strong>Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks</strong>.” arXiv preprint arXiv:1603.01768 (2016). <a href="http://arxiv.org/pdf/1603.01768" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Neural Doodle)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[5]</strong> Zhang, Richard, Phillip Isola, and Alexei A. Efros. “<strong>Colorful Image Colorization</strong>.” arXiv preprint arXiv:1603.08511 (2016). <a href="http://arxiv.org/pdf/1603.08511" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[6]</strong> Johnson, Justin, Alexandre Alahi, and Li Fei-Fei. “<strong>Perceptual losses for real-time style transfer and super-resolution</strong>.” arXiv preprint arXiv:1603.08155 (2016). <a href="https://arxiv.org/pdf/1603.08155.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[7]</strong> Vincent Dumoulin, Jonathon Shlens and Manjunath Kudlur. “<strong>A learned representation for artistic style</strong>.” arXiv preprint arXiv:1610.07629 (2016). <a href="https://arxiv.org/pdf/1610.07629v1.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[8]</strong> Gatys, Leon and Ecker, et al.”<strong>Controlling Perceptual Factors in Neural Style Transfer</strong>.” arXiv preprint arXiv:1611.07865 (2016). <a href="https://arxiv.org/pdf/1611.07865.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(control style transfer over spatial location,colour information and across spatial scale)</strong><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[9]</strong> Ulyanov, Dmitry and Lebedev, Vadim, et al. “<strong>Texture Networks: Feed-forward Synthesis of Textures and Stylized Images</strong>.” arXiv preprint arXiv:1603.03417(2016). <a href="http://arxiv.org/abs/1603.03417" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(texture generation and style transfer)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[10]</strong> Yijun Li, Ming-Yu Liu ,Xueting Li, Ming-Hsuan Yang,Jan Kautz (NVIDIA). “<strong>A Closed-form Solution to Photorealistic Image Stylization</strong>.” arXiv preprint arXiv:1802.06474(2018). <a href="https://arxiv.org/pdf/1802.06474.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <strong>(Very fast and ultra realistic style transfer)</strong> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

<h4 id="38---object-segmentation">3.8 - Object Segmentation</h4>

<ul>
  <li>
    <p><strong>[1]</strong> J. Long, E. Shelhamer, and T. Darrell, “<strong>Fully convolutional networks for semantic segmentation</strong>.” in CVPR, 2015. <a href="https://arxiv.org/pdf/1411.4038v2.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[2]</strong> L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. “<strong>Semantic image segmentation with deep convolutional nets and fully connected crfs</strong>.” In ICLR, 2015. <a href="https://arxiv.org/pdf/1606.00915v1.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[3]</strong> Pinheiro, P.O., Collobert, R., Dollar, P. “<strong>Learning to segment object candidates.</strong>” In: NIPS. 2015. <a href="https://arxiv.org/pdf/1506.06204v2.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[4]</strong> Dai, J., He, K., Sun, J. “<strong>Instance-aware semantic segmentation via multi-task network cascades</strong>.” in CVPR. 2016 <a href="https://arxiv.org/pdf/1512.04412v1.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
  <li>
    <p><strong>[5]</strong> Dai, J., He, K., Sun, J. “<strong>Instance-sensitive Fully Convolutional Networks</strong>.” arXiv preprint arXiv:1603.08678 (2016). <a href="https://arxiv.org/pdf/1603.08678v1.pdf" rel="external nofollow noopener" target="_blank">[pdf]</a> <img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"><img class="emoji" title=":star:" alt=":star:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b50.png" height="20" width="20"></p>
  </li>
</ul>

  </article>
</div>

    </div>

    <!-- Footer -->    <!-- ORIGINAL CODE -->
    <!-- <footer class="sticky-bottom mt-5">
      <div class="container">
        &copy; Copyright 2023 Bradley M. Cardona. Last updated: April 18, 2023.
      </div>
    </footer> -->

    
    
    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2023 Bradley M. Cardona.
        
        
        
        Last updated: April 18, 2023.
        
      </div>
    </footer>
    

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
